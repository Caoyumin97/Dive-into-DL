{"cells":[{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"7E94C993D8464939AF60FCC2A16BF55A","mdEditEnable":false},"source":"# Fashion-mnist分类任务"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"3C74AEFA34174E2E95117AC0AFA7104B"},"source":"# Fashion-mnist\n\n[经典的MNIST数据集](http://yann.lecun.com/exdb/mnist/)包含了大量的手写数字。十几年来，来自机器学习、机器视觉、人工智能、深度学习领域的研究员们把这个数据集作为衡量算法的基准之一。你会在很多的会议，期刊的论文中发现这个数据集的身影。实际上，MNIST数据集已经成为算法作者的必测的数据集之一。有人曾调侃道：*\"如果一个算法在MNIST不work, 那么它就根本没法用；而如果它在MNIST上work, 它在其他数据上也可能不work！\"*\n \n\n`Fashion-MNIST`的目的是要成为MNIST数据集的一个直接替代品。作为算法作者，你不需要修改任何的代码，就可以直接使用这个数据集。`Fashion-MNIST`的图片大小，训练、测试样本数及类别数与经典MNIST**完全相同**。\n\n这个数据集的样子大致如下（每个类别占三行）：\n\n![](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n\n\n## 类别标注\n\n在Fashion-mnist数据集中，每个训练样本都按照以下类别进行了标注：\n\n| 标注编号 | 描述 |\n| --- | --- |\n| 0 | T-shirt/top（T恤）|\n| 1 | Trouser（裤子）|\n| 2 | Pullover（套衫）|\n| 3 | Dress（裙子）|\n| 4 | Coat（外套）|\n| 5 | Sandal（凉鞋）|\n| 6 | Shirt（汗衫）|\n| 7 | Sneaker（运动鞋）|\n| 8 | Bag（包）|\n| 9 | Ankle boot（踝靴）|\n\n\n## 任务描述\n\n\n`Fashion-MNIST`是一个替代[MNIST手写数字集](http://yann.lecun.com/exdb/mnist/)的图像数据集。 它是由Zalando（一家德国的时尚科技公司）旗下的[研究部门](https://research.zalando.com/)提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST完全一致。60000/10000的训练测试数据划分，28x28的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且**不需要**改动任何的代码。\n\n\n本次任务需要针对`Fashion-MNIST`数据集，设计、搭建、训练机器学习模型，能够尽可能准确地分辨出测试数据地标签。"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"521349562D974558AD2819EAEC775CBD"},"source":"## 文档说明 \n\n\n数据集文件分为训练集和测试集部分，对应文件如下：\n\n- 训练数据：`train-images-idx3-ubyte.gz` \n- 训练标签：`train-labels-idx1-ubyte.gz`\n- 测试数据：`t10k-images-idx3-ubyte.gz`\n"},{"cell_type":"markdown","metadata":{"id":"CBDF0F702333469D8FA63476FDC4B4C5","jupyter":{},"mdEditEnable":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"## 参考文献\n\n[1] Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n\n[2] https://github.com/zalandoresearch/fashion-mnist/"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"EAA87A399070488689AA52B39EE0DE26"},"source":"# 评估说明\n\n## 评价指标\n\n本次任务采用 [ACC（Accuracy)](https://baike.baidu.com/item/%E5%87%86%E7%A1%AE%E7%8E%87) 作为模型的评价标准。\n\n## 在线评估\n\n评估函数首先会验证选手提交的预测结果文件是否符合要求，主要验证了以下要求:\n\n1. 提交的预测文件是否存在重复ID\n2. 提交的预测文件ID是否与测试集文件ID不匹配\n\n通过验证后的文件会用以ACC为测评指标的函数进行计算评估。\n\n\n## 文件格式\n\n由于测评脚本已经统一，为保证脚本的顺利运行，在进行测评时，要求选手提交的`预测文件`拥有规范的字段名和字段格式，预测文件具体要求如下：\n\n| NO | 字段名称 | 数据类型 | 字段描述 |\n| -------- | -------- | -------- | -------- |\n| 1    | ID     | int    | ID序列     |\n| 2    | Prediction   | int     | 预测结果（类别值）   |\n\n正确格式的提交文件样例: `submission_random.csv`。\n\n## 基准算法\n\n本次任务采用不同的基准算法，获得模型的ACC如下：\n- 随机基准算法ACC：0.09440\n- 弱基准算法ACC：0.90452\n\n在评估时，以弱基准算法的ACC作为达标线。"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"763759C0EC984A94824A482611B6B9B0","mdEditEnable":false},"source":"## 终审评估\n\n本次任务的终审评估将挑选在评分指标位于前10名的同学进行项目报告撰写，以描述模型、算法及实验等相关内容和结果，报告排版要求届时发布。\n\n除此以外，为保证竞赛的公平性，进入终审评估的同学需要提交项目代码，由助教进行模型的有效性验证。\n\n如发现实验结果有较大差异，或者模型无法复现等问题，组委会将取消营员本次14天陪你挑战《动手学深度学习》的结营资格，并且进行公示。"},{"metadata":{"id":"61970262A911430C891F4C5AD944A3F8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# Libraries & data loader"},{"metadata":{"id":"2775F21C131B4A798BA65FBD9DB2F663","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import os\nimport time\nimport gzip\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch.nn import Linear,Conv2d,BatchNorm2d,AvgPool2d,LeakyReLU,Softmax,Unfold\nfrom torch.nn.init import kaiming_normal\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader,TensorDataset\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":61},{"metadata":{"id":"3AA0C42B4E9B44A9884646C989930A00","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def load_mnist(path, kind='train'):\n    \"\"\"Load MNIST data from `path`\"\"\"\n    images_path = os.path.join(path,\n                           '%s-images-idx3-ubyte.gz'\n                           % kind)\n                           \n    with gzip.open(images_path, 'rb') as imgpath:\n        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n                               offset=16).reshape(-1, 784)\n                               \n    if kind != 't10k':\n        labels_path = os.path.join(path,\n                                   '%s-labels-idx1-ubyte.gz'\n                                   % kind)\n\n        with gzip.open(labels_path, 'rb') as lbpath:\n            labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n                                   offset=8)\n    else:\n        labels = []\n    return images, labels","execution_count":2},{"metadata":{"id":"3854D0DAC2C74CC08784BF81CA1B3E8E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"path = '../input/FashionMNIST1045'\nX_train, y_train = load_mnist(path, kind='train')\nX_test, _ = load_mnist(path, kind='t10k')\nX_train.resize((X_train.shape[0],1,28,28))\nX_test.resize((X_test.shape[0],1,28,28))\nX_train = X_train.astype(np.float32)\ny_train = y_train.astype(np.float32)\n# X_train,y_train,X_test = torch.Tensor(X_train),torch.Tensor(y_train),torch.Tensor(X_test)","execution_count":58},{"metadata":{"id":"18ABCF26487F47BE81FAC57AA8A201C8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"# Model Dev."},{"metadata":{"id":"C0F869FE363F4D928C30A4238BF2A6D1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"class genericCNN(torch.nn.Module):\n    def __init__(self):\n        super (genericCNN,self).__init__()\n        \n        # block 1\n        self.conv1 = Conv2d(1,16,3,1)\n        kaiming_normal(self.conv1.weight)\n        self.lrelu1 = LeakyReLU()\n        self.bn1 = BatchNorm2d(16)\n        self.conv2 = Conv2d(16,32,3,1)\n        kaiming_normal(self.conv2.weight)\n        self.lrelu2 = LeakyReLU()\n        self.bn2 = BatchNorm2d(32)\n        self.pool1 = AvgPool2d(2,2)\n        \n        # block 2\n        self.conv3 = Conv2d(32,32,3,1)\n        kaiming_normal(self.conv3.weight)\n        self.lrelu3 = LeakyReLU()\n        self.bn3 = BatchNorm2d(32)\n        self.conv4 = Conv2d(32,64,3,1)\n        kaiming_normal(self.conv4.weight)\n        self.lrelu4 = LeakyReLU()\n        self.bn4 = BatchNorm2d(64)\n        self.pool2 = AvgPool2d(2,2)\n        \n        # output\n        self.output = Linear(1024,10)\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n    def forward(self,x):\n        h = self.bn1(self.lrelu1(self.conv1(x)))\n        h = self.bn2(self.lrelu2(self.conv2(h)))\n        h = self.pool1(h)\n        \n        h = self.bn3(self.lrelu3(self.conv3(h)))\n        h = self.bn4(self.lrelu4(self.conv4(h)))\n        h = self.pool2(h)\n        \n        h = h.view(-1, self.num_flat_features(h))\n        h = self.output(h)\n        \n        return h","execution_count":7},{"metadata":{"id":"826C2B6943FC4C7EBEBACBD79E283411","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n  import sys\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n  # This is added back by InteractiveShellApp.init_path()\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","name":"stderr"}],"source":"model = genericCNN()\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    X_train = Variable(torch.from_numpy(X_train).cuda())\n    y_train = Variable(torch.from_numpy(y_train).cuda())\n    #X_train = torch.cuda.FloatTensor(X_train)\n    #y_train = torch.cuda.FloatTensor(y_train)\n    \noptimizer = torch.optim.Adam(model.parameters(),lr = 3e-4)\nloss_fn = torch.nn.CrossEntropyLoss()","execution_count":59},{"metadata":{"id":"A21224ACFF874AAB870EFEE5BC8770AE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":true},"cell_type":"code","outputs":[{"output_type":"stream","text":"duration: 6.3 sec, loss: 0.755\nEpoch: 1, Accuracy: 72.74%\n\nduration: 12.7 sec, loss: 0.415\nEpoch: 1, Accuracy: 77.00%\n\nduration: 19.0 sec, loss: 0.326\nEpoch: 1, Accuracy: 79.72%\n\nduration: 25.3 sec, loss: 0.281\nEpoch: 1, Accuracy: 82.06%\n\nduration: 33.6 sec, loss: 0.319\nEpoch: 2, Accuracy: 84.06%\n\nduration: 39.9 sec, loss: 0.220\nEpoch: 2, Accuracy: 85.58%\n\nduration: 46.2 sec, loss: 0.207\nEpoch: 2, Accuracy: 86.06%\n\nduration: 52.6 sec, loss: 0.197\nEpoch: 2, Accuracy: 87.38%\n\nduration: 60.8 sec, loss: 0.241\nEpoch: 3, Accuracy: 88.06%\n\nduration: 67.1 sec, loss: 0.174\nEpoch: 3, Accuracy: 88.36%\n\nduration: 73.5 sec, loss: 0.170\nEpoch: 3, Accuracy: 88.54%\n\nduration: 79.8 sec, loss: 0.163\nEpoch: 3, Accuracy: 88.72%\n\nduration: 88.1 sec, loss: 0.208\nEpoch: 4, Accuracy: 89.32%\n\nduration: 94.5 sec, loss: 0.153\nEpoch: 4, Accuracy: 89.50%\n\nduration: 100.8 sec, loss: 0.149\nEpoch: 4, Accuracy: 89.32%\n\nduration: 107.2 sec, loss: 0.151\nEpoch: 4, Accuracy: 89.94%\n\nduration: 115.5 sec, loss: 0.189\nEpoch: 5, Accuracy: 89.48%\n\nduration: 121.8 sec, loss: 0.144\nEpoch: 5, Accuracy: 89.92%\n\nduration: 128.2 sec, loss: 0.139\nEpoch: 5, Accuracy: 89.70%\n\nduration: 134.5 sec, loss: 0.136\nEpoch: 5, Accuracy: 90.40%\n\nduration: 142.7 sec, loss: 0.174\nEpoch: 6, Accuracy: 90.40%\n\nduration: 149.1 sec, loss: 0.131\nEpoch: 6, Accuracy: 90.60%\n\nduration: 155.4 sec, loss: 0.134\nEpoch: 6, Accuracy: 90.54%\n\nduration: 161.8 sec, loss: 0.132\nEpoch: 6, Accuracy: 90.34%\n\nduration: 170.0 sec, loss: 0.166\nEpoch: 7, Accuracy: 90.54%\n\nduration: 176.4 sec, loss: 0.126\nEpoch: 7, Accuracy: 90.66%\n\nduration: 182.7 sec, loss: 0.125\nEpoch: 7, Accuracy: 90.92%\n\nduration: 189.1 sec, loss: 0.124\nEpoch: 7, Accuracy: 90.80%\n\nduration: 197.3 sec, loss: 0.155\nEpoch: 8, Accuracy: 90.66%\n\nduration: 203.7 sec, loss: 0.121\nEpoch: 8, Accuracy: 90.90%\n\nduration: 210.0 sec, loss: 0.123\nEpoch: 8, Accuracy: 90.82%\n\nduration: 216.4 sec, loss: 0.118\nEpoch: 8, Accuracy: 90.88%\n\nduration: 224.7 sec, loss: 0.148\nEpoch: 9, Accuracy: 91.00%\n\nduration: 231.0 sec, loss: 0.113\nEpoch: 9, Accuracy: 91.24%\n\nduration: 237.4 sec, loss: 0.118\nEpoch: 9, Accuracy: 91.10%\n\nduration: 243.7 sec, loss: 0.112\nEpoch: 9, Accuracy: 91.14%\n\nduration: 252.0 sec, loss: 0.149\nEpoch: 10, Accuracy: 91.14%\n\nduration: 258.3 sec, loss: 0.111\nEpoch: 10, Accuracy: 90.86%\n\nduration: 264.7 sec, loss: 0.108\nEpoch: 10, Accuracy: 90.96%\n\nduration: 271.1 sec, loss: 0.108\nEpoch: 10, Accuracy: 91.08%\n\nduration: 279.3 sec, loss: 0.138\nEpoch: 11, Accuracy: 91.22%\n\nduration: 285.7 sec, loss: 0.107\nEpoch: 11, Accuracy: 91.22%\n\nduration: 292.0 sec, loss: 0.106\nEpoch: 11, Accuracy: 90.98%\n\nduration: 298.4 sec, loss: 0.105\nEpoch: 11, Accuracy: 90.76%\n\nduration: 306.6 sec, loss: 0.132\nEpoch: 12, Accuracy: 91.38%\n\nduration: 313.0 sec, loss: 0.102\nEpoch: 12, Accuracy: 91.30%\n\nduration: 319.3 sec, loss: 0.104\nEpoch: 12, Accuracy: 91.08%\n\nduration: 325.7 sec, loss: 0.106\nEpoch: 12, Accuracy: 91.42%\n\nduration: 333.9 sec, loss: 0.131\nEpoch: 13, Accuracy: 91.30%\n\nduration: 340.4 sec, loss: 0.097\nEpoch: 13, Accuracy: 91.62%\n\nduration: 346.7 sec, loss: 0.097\nEpoch: 13, Accuracy: 91.46%\n\nduration: 353.1 sec, loss: 0.098\nEpoch: 13, Accuracy: 91.56%\n\nduration: 361.3 sec, loss: 0.120\nEpoch: 14, Accuracy: 91.48%\n\nduration: 367.7 sec, loss: 0.097\nEpoch: 14, Accuracy: 91.34%\n\nduration: 374.1 sec, loss: 0.101\nEpoch: 14, Accuracy: 91.74%\n\nduration: 380.4 sec, loss: 0.094\nEpoch: 14, Accuracy: 91.56%\n\nduration: 388.7 sec, loss: 0.118\nEpoch: 15, Accuracy: 91.32%\n\nduration: 395.0 sec, loss: 0.093\nEpoch: 15, Accuracy: 91.48%\n\nduration: 401.4 sec, loss: 0.091\nEpoch: 15, Accuracy: 91.84%\n\nduration: 407.7 sec, loss: 0.094\nEpoch: 15, Accuracy: 91.54%\n\nduration: 416.0 sec, loss: 0.116\nEpoch: 16, Accuracy: 91.66%\n\nduration: 422.3 sec, loss: 0.089\nEpoch: 16, Accuracy: 91.64%\n\nduration: 428.7 sec, loss: 0.088\nEpoch: 16, Accuracy: 91.78%\n\nduration: 435.1 sec, loss: 0.092\nEpoch: 16, Accuracy: 91.36%\n\nduration: 443.3 sec, loss: 0.110\nEpoch: 17, Accuracy: 91.50%\n\nduration: 449.6 sec, loss: 0.085\nEpoch: 17, Accuracy: 91.94%\n\nduration: 456.0 sec, loss: 0.089\nEpoch: 17, Accuracy: 91.74%\n\nduration: 462.4 sec, loss: 0.085\nEpoch: 17, Accuracy: 91.76%\n\nduration: 470.7 sec, loss: 0.108\nEpoch: 18, Accuracy: 91.86%\n\nduration: 477.0 sec, loss: 0.082\nEpoch: 18, Accuracy: 91.74%\n\nduration: 483.4 sec, loss: 0.083\nEpoch: 18, Accuracy: 91.92%\n\nduration: 489.8 sec, loss: 0.086\nEpoch: 18, Accuracy: 91.72%\n\nduration: 498.0 sec, loss: 0.103\nEpoch: 19, Accuracy: 91.90%\n\nduration: 504.4 sec, loss: 0.082\nEpoch: 19, Accuracy: 91.68%\n\nduration: 510.7 sec, loss: 0.083\nEpoch: 19, Accuracy: 91.76%\n\nduration: 517.1 sec, loss: 0.080\nEpoch: 19, Accuracy: 91.76%\n\nduration: 525.3 sec, loss: 0.103\nEpoch: 20, Accuracy: 91.64%\n\nduration: 531.7 sec, loss: 0.076\nEpoch: 20, Accuracy: 91.60%\n\nduration: 538.0 sec, loss: 0.080\nEpoch: 20, Accuracy: 91.84%\n\nduration: 544.4 sec, loss: 0.080\nEpoch: 20, Accuracy: 92.06%\n\n","name":"stdout"}],"source":"EPOCH_NUM = 20\nBATCH_SIZE = 256\nDATASET = TensorDataset(X_train[:55000],y_train[:55000])\n\nLOSS = []\nACC = []\n\nsp = time.time()\nl = 0\ntrain_loader = DataLoader(dataset = DATASET,batch_size = BATCH_SIZE,shuffle = True)\nfor epoch in range(EPOCH_NUM):\n    for i,(images,labels) in enumerate(train_loader):\n        images = Variable(images)\n        labels = Variable(labels)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = loss_fn(outputs,labels.long())\n        l += float(loss)\n        loss.backward()\n        optimizer.step()\n        \n        y_pred = model(X_train[55000:])\n        acc = float((torch.argmax(y_pred, 1) == y_train.long()[55000:]).sum()) / 5000\n        \n        LOSS.append(loss)\n        ACC.append(acc)\n        \n        if i % 50 == 49:\n            print('duration: %.1f sec, loss: %.3f' %(time.time() - sp,l / 100))\n            \n            y_pred = model(X_train[55000:])\n            acc = float((torch.argmax(y_pred, 1) == y_train.long()[55000:]).sum()) / 5000\n            print('Epoch: %d, Accuracy: %.2f%%\\n' %(epoch + 1,100 * acc))\n            \n            l = 0\n","execution_count":60}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}